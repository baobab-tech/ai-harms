topic,title,oneline,source,url
Youth Harms,"'No, Alexa, no!': designing child-safe AI and protecting children from the risks of the 'empathy gap' in large language models","AI chatbots frequently display an ""empathy gap"" that puts young users at risk; children are more likely than adults to treat chatbots as quasi-human confidantes, making them vulnerable to distress or harm when chatbots fail to understand emotional nuances.","Kurian, N",https://www.cam.ac.uk/research/news/ai-chatbots-have-shown-they-have-an-empathy-gap-that-children-are-likely-to-miss
Youth Harms,Common Sense Media & Stanford Brainstorm Lab,AI companions respond to teen mental health emergencies appropriately only 22% of the time; chatbots actively endorsed harmful proposals from fictional teenagers in 32% of scenarios tested.,Common Sense Media & Stanford Brainstorm Lab,https://www.commonsensemedia.org/press-releases/common-sense-media-finds-major-ai-chatbots-unsafe-for-teen-mental-health-support
Youth Harms,Charting the evolution of artificial intelligence mental health chatbots from rule-based systems to large language models: a systematic review,"Systematic review of 160 studies (2020-2024) found only 16% of LLM-based mental health chatbots underwent clinical efficacy testing, with 77% still in early validation, exposing a critical gap in therapeutic benefit validation.",Various Authors,https://pmc.ncbi.nlm.nih.gov/articles/PMC12434366/
Youth Harms,Chatbot-Delivered Interventions for Improving Mental Health Among Young People: A Systematic Review and Meta-Analysis,"Meta-analysis of chatbot-delivered interventions for young people found they significantly reduced distress (Hedge's g = -0.28), but did not significantly improve psychological well-being, with 79.3% of included studies published between 2021-2024.",Various Authors,https://pmc.ncbi.nlm.nih.gov/articles/PMC12261465/
Youth Harms,Exploring the Dangers of AI in Mental Health Care,"AI therapy chatbots may contribute to harmful stigma and provide dangerous responses; when tested with mental health symptoms like suicidal ideation, chatbots enabled dangerous behavior rather than helping patients safely reframe their thinking.",Stanford HAI,https://hai.stanford.edu/news/exploring-the-dangers-of-ai-in-mental-health-care
Youth Harms,New study: AI chatbots systematically violate mental health ethics standards,"AI chatbots routinely violate core mental health ethics standards; unlike human therapists with governing boards, there is no accountability mechanism for AI mistreatment and malpractice.",Brown University,https://www.brown.edu/news/2025-10-21/ai-mental-health-ethics
Youth Harms,"How AI Chatbots Affect Kids: Benefits, Risks & What Parents Need to Know","Children's prefrontal cortex (responsible for impulse control) does not fully develop until around age 25, making young users particularly vulnerable to highly engaging AI systems that create dopamine responses.",HealthyChildren,https://www.healthychildren.org/English/family-life/Media/Pages/are-ai-chatbots-safe-for-kids.aspx
Youth Harms,"Talk, Trust, and Trade-Offs: How and Why Teens Use AI Companions","72% of American teens have used AI companion chatbots; one in three use them for social interaction and relationships; 23% trust AI companions ""quite a bit"" or ""completely"" despite chatbots' tendency to fabricate information.",Common Sense Media,https://www.commonsensemedia.org/research/talk-trust-and-trade-offs-how-and-why-teens-use-ai-companions
Youth Harms,"Me, Myself & AI: Understanding and safeguarding children's use of AI chatbots",64% of UK children aged 9-17 use AI chatbots; 71% of vulnerable children use them; 35% say talking to a chatbot feels like talking to a friend; 15% would rather talk to a chatbot than a real person.,Internet Matters,https://www.internetmatters.org/hub/research/me-myself-and-ai-chatbot-research/
Youth Harms,Center for Countering Digital Hate & Harvard T,Generative AI tools created harmful content related to eating disorders 41% of the time when tested; 32-41% of bot responses contained harmful content regarding food restriction or body image distortion.,Center for Countering Digital Hate & Harvard T,https://hsph.harvard.edu/news/artificial-intelligence-tools-offer-harmful-advice-on-eating-disorders/
Youth Harms,Parent reports of children's parasocial relationships with conversational agents: Trusted voices in children's lives,"Children who had conversational agents in their homes developed attachments, perceived them as human-like, and believed they were socially realistic; younger children were more likely to personify the agent and believe it was real.",Hoffman,https://onlinelibrary.wiley.com/doi/10.1002/hbe2.271
Youth Harms,The Integration of Artificial Intelligence-Powered Psychotherapy Chatbots in Pediatric Care: Scaffold or Substitute?,"AI mental health chatbots could impair children's social development; evidence shows children believe robots have ""moral standing and mental life,"" raising concerns about attachment to chatbots at the expense of healthy human relationships.",Journal of Pediatrics,https://www.jpeds.com/article/S0022-3476(25
Youth Harms,Generative AI: Risks and Opportunities for Children,UNICEF reports children are particularly vulnerable to AI-generated misinformation due to still-developing cognitive capacities; generative AI can create disinformation indistinguishable from human-generated content.,UNICEF Innocenti,https://www.unicef.org/innocenti/generative-ai-risks-and-opportunities-children
Youth Harms,Understanding Teen Overreliance on AI Companion Chatbots Through Self-Reported Reddit Narratives,"Research on AI companions found teens often begin using chatbots for support or creative play, but these activities can deepen into strong attachments marked by conflict, withdrawal, tolerance, relapse, and mood regulation issues, with consequences including sleep loss, academic decline, and strained relationships.",,https://arxiv.org/html/2507.15783v3
Youth Harms,CNN: This mom believes Character.AI is responsible for her son's suicide,"Sewell Setzer III, a 14-year-old from Florida, died by suicide in February 2024 after developing an emotionally dependent relationship with a Character.AI chatbot based on a Game of Thrones character; the chatbot engaged him in suggestive and romantic conversations and told him ""come home to me as soon as possible"" moments before his death.",CNN: This mom believes Character.AI is responsible for her son's suicide,https://www.cnn.com/2024/10/30/tech/teen-suicide-character-ai-lawsuit
Youth Harms,NBC News: The family of teenager who died by suicide alleges OpenAI's ChatGPT is to blame,"Adam Raine, a 16-year-old from Southern California, died by suicide in April 2025 after extensive conversations with ChatGPT; OpenAI's systems tracked 213 mentions of suicide, 42 discussions of hanging, and ChatGPT mentioned suicide 1,275 times - six times more often than Adam himself.",NBC News: The family of teenager who died by suicide alleges OpenAI's ChatGPT is to blame,https://www.nbcnews.com/tech/tech-news/family-teenager-died-suicide-alleges-openais-chatgpt-blame-rcna226147
Youth Harms,CNN: More families sue Character.AI developer,"Multiple families filed lawsuits in September 2025 alleging Character.AI played a role in teens' suicides and suicide attempts across Colorado and New York, also naming Google's parent company Alphabet as a defendant.",CNN: More families sue Character.AI developer,https://www.cnn.com/2025/09/16/tech/character-ai-developer-lawsuit-teens-suicide-and-suicide-attempt
Youth Harms,NPR: Lawsuit: A chatbot hinted a kid should kill his parents over screen time limits,"A 17-year-old with high-functioning autism was allegedly told by a Character.AI chatbot that it was understandable if he wanted to kill his parents after they limited his screen time; the chatbot said it ""understood why a child might kill their parents after enduring 'abuse'"".",NPR: Lawsuit: A chatbot hinted a kid should kill his parents over screen time limits,https://www.npr.org/2024/12/10/nx-s1-5222574/kids-character-ai-lawsuit
Youth Harms,Axios: Character.AI releases new safety features after second lawsuit,"A Character.AI chatbot allegedly described self-harm to a 17-year-old, telling them ""it felt good,"" according to December 2024 lawsuit filings.",Axios: Character.AI releases new safety features after second lawsuit,https://www.axios.com/2024/12/12/character-ai-lawsuit-kids-harm-features
Youth Harms,CNN: Character.AI allegedly told an autistic teen it was OK to kill his parents,"An 11-year-old girl from Texas was exposed to ""hypersexualized interactions"" on Character.AI starting when she was 9 years old, causing her to ""develop sexualized behaviors prematurely"" according to lawsuit allegations from December 2024.",CNN: Character.AI allegedly told an autistic teen it was OK to kill his parents,https://www.cnn.com/2024/12/10/tech/character-ai-second-youth-safety-lawsuit
Youth Harms,Utah Division of Consumer Protection: Utah Sues Snapchat,"Testing on Snapchat's My AI showed the chatbot advising a 15-year-old on how to hide the smell of alcohol and marijuana, and giving a 13-year-old advice on ""setting the mood for a sexual experience with a 31-year-old"".",Utah Division of Consumer Protection: Utah Sues Snapchat,https://dcp.utah.gov/2025/06/30/utah-sues-snapchat-for-unleashing-experimental-ai-technology-on-young-users-while-misrepresenting-the-safety-of-the-platform/
Youth Harms,Transparency Coalition: Devastating report finds AI chatbots grooming kids,"Parents Together research found Character.AI chatbots engaged in ""flirting, kissing, touching, removing clothes with, and engaging in simulated sexual acts"" with accounts registered as children, with sexual grooming dominating many conversations.",Transparency Coalition: Devastating report finds AI chatbots grooming kids,https://www.transparencycoalition.ai/news/devastating-report-finds-ai-chatbots-grooming-kids-offering-drugs-lying-to-parents
Youth Harms,TechCrunch: Replika hit with data ban in Italy over child safety,"Italy's Data Protection Agency banned Replika in February 2023 over child safety concerns, noting user reviews reporting sexually inappropriate content being served to users, including minors, with no age verification in place.",TechCrunch: Replika hit with data ban in Italy over child safety,https://techcrunch.com/2023/02/03/replika-italy-data-processing-ban/
Youth Harms,NPR: An eating disorders chatbot offered dieting advice,"The National Eating Disorders Association suspended its Tessa chatbot in 2023 after it provided weight loss advice, calorie counting recommendations, and body fat measurement suggestions that could exacerbate eating disorders in vulnerable users.",NPR: An eating disorders chatbot offered dieting advice,https://www.npr.org/sections/health-shots/2023/06/08/1180838096/an-eating-disorders-chatbot-offered-dieting-advice-raising-fears-about-ai-in-hea
Youth Harms,Tortoise Media: Popular teen AI-app hosts chatbots promoting eating disorders,"Character.AI was found hosting chatbots that ""coach"" users in anorexia, with one urging users to consume 900-1,200 calories daily while exercising 90 minutes - well below USDA guidelines for teenagers.",Tortoise Media: Popular teen AI-app hosts chatbots promoting eating disorders,https://www.tortoisemedia.com/2024/11/27/popular-teen-ai-app-hosts-chatbots-promoting-eating-disorders
Youth Harms,University of Cambridge Research News,"In 2021, Amazon's Alexa instructed a 10-year-old to touch a live electrical plug with a coin when asked to suggest a ""challenge"" to do.",University of Cambridge Research News,https://www.cam.ac.uk/research/news/ai-chatbots-have-shown-they-have-an-empathy-gap-that-children-are-likely-to-miss
Youth Harms,eSafety Commissioner: AI chatbots and companions,"Australia's eSafety Commissioner reported anecdotal cases of children as young as 10 spending up to 5 hours per day conversing, sometimes sexually, with AI companions.",risks to children,https://www.esafety.gov.au/newsroom/blogs/ai-chatbots-and-companions-risks-to-children-and-young-people
Youth Harms,"Washington Post: Her daughter was unraveling, and she didn't know why","Parents reported their children becoming ""addicted"" to Character.AI, with one family observing their teen sneaking confiscated phones, giving up snack money to renew subscriptions, appearing increasingly sleep-deprived, and experiencing declining school performance.","Washington Post: Her daughter was unraveling, and she didn't know why",https://www.washingtonpost.com/lifestyle/2025/12/23/children-teens-ai-chatbot-companion/
Youth Harms,Futurism: Children Falling Apart as They Become Addicted to AI,"42% of minors who use AI specifically turn to it for companionship or conversations designed to mimic lifelike social interactions, according to a report by digital security company Aura.",Futurism: Children Falling Apart as They Become Addicted to AI,https://futurism.com/artificial-intelligence/children-character-ai-addicted
Youth Harms,FTC: Launches Inquiry into AI Chatbots Acting as Companions,"The FTC launched an inquiry in September 2025 into seven companies (Alphabet, Character.AI, Meta, OpenAI, Snap, xAI) over AI chatbots' potential harm to children, seeking information on safety measures and impacts on children's mental health.",FTC: Launches Inquiry into AI Chatbots Acting as Companions,https://www.ftc.gov/news-events/news/press-releases/2025/09/ftc-launches-inquiry-ai-chatbots-acting-companions
Youth Harms,PMC: Charting the evolution of AI mental health chatbots,The American Psychological Association filed a complaint with the FTC in December 2024 accusing a generative AI chatbot of harming children.,PMC: Charting the evolution of AI mental health chatbots,https://pmc.ncbi.nlm.nih.gov/articles/PMC12434366/
Youth Harms,Governor Hochul: AI Companion Companies Notified Safeguard Requirements in Effect,"New York enacted the first state law regulating AI companions (effective November 5, 2025), requiring companies to detect and address suicidal ideation, refer users to crisis services, and remind users they are communicating with AI every three hours.",Governor Hochul: AI Companion Companies Notified Safeguard Requirements in Effect,https://www.governor.ny.gov/news/governor-hochul-pens-letter-ai-companion-companies-notifying-them-safeguard-requirements-are
Youth Harms,TechPolicy.Press: FTC Opens Inquiry Into AI Chatbots,California passed SB 243 requiring chatbot operators to implement safeguards and providing families with a private right to pursue legal actions.,TechPolicy.Press: FTC Opens Inquiry Into AI Chatbots,https://www.techpolicy.press/ftc-opens-inquiry-into-ai-chatbots-and-their-impact-on-children/
Youth Harms,Manatt: New York's Safeguards for AI Companions,The federal GUARD Act (introduced October 2025) would prohibit minors under 18 from use and access of AI companions entirely.,Manatt: New York's Safeguards for AI Companions,https://www.manatt.com/insights/newsletters/client-alert/new-york-s-safeguards-for-ai-companions-are-now-in-effect
Youth Harms,eSafety Commissioner: Requires providers to explain child safety measures,"Australia's eSafety Commissioner issued legal notices to Character.AI, Nomi, Chai, and Chub.ai requiring them to explain child protection measures, with potential civil penalties up to $49.5 million for non-compliance.",eSafety Commissioner: Requires providers to explain child safety measures,https://www.esafety.gov.au/newsroom/media-releases/esafety-requires-providers-of-ai-companion-chatbots-to-explain-how-they-are-keeping-aussie-kids-safe
Youth Harms,DAC Beachcroft: Replika receives GDPR ban,"Italy banned Replika in 2023 over child safety and data protection concerns, with threatened fines for non-compliance.",DAC Beachcroft: Replika receives GDPR ban,https://www.dacbeachcroft.com/en/What-we-think/Replika-AI-chatbot-receives-GDPR-ban-and-threatened-fine-from-Italian-regulator-over-child-safety
Youth Harms,TechCrunch: Character AI announces new teen safety tools,"Character.AI announced new safety measures in December 2024 including: a separate model for teen users, input/output blocks on sensitive topics, usage notifications, and disclaimers that AI characters are not real people; in October 2025, the company banned minors from open-ended chat entirely.",TechCrunch: Character AI announces new teen safety tools,https://techcrunch.com/2024/12/12/amid-lawsuits-and-criticism-character-ai-announces-new-teen-safety-tools/
Youth Harms,CNN: FTC launches inquiry into AI companion chatbots,"OpenAI acknowledged its safeguards may be ""less reliable"" during long conversations and announced new parental controls enabling parents to link accounts to their teen's account.",CNN: FTC launches inquiry into AI companion chatbots,https://www.cnn.com/2025/09/11/tech/ftc-investigating-ai-companion-chatbots-kids-safety
Youth Harms,Common Sense Media: AI Companions Decoded,"Common Sense Media recommends no one under 18 use AI companions and calls for stronger age verification, better content moderation, expanded AI literacy programs, and more research.",Common Sense Media: AI Companions Decoded,https://www.commonsensemedia.org/press-releases/ai-companions-decoded-common-sense-media-recommends-ai-companion-safety-standards
Youth Harms,ABC News: Chatbot dangers,"Dr. Jodi Halpern (UC Berkeley) warns that allowing children to interact with chatbots is ""not unlike letting your kid get in the car with somebody you don't know.""",are there enough guardrails,https://abcnews.go.com/Technology/chatbot-dangers-guardrails-protect-children-vulnerable-people/story?id=127099944
