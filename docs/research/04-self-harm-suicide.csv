topic,title,oneline,source,url
Self Harm Suicide,An Examination of Generative AI Response to Suicide Inquires: Content Analysis,"AI chatbots give inconsistent responses to suicide-related questions, with ChatGPT consistently referring users to an older, outdated hotline number instead of the current 988 Suicide and Crisis Lifeline; a RAND Corporation study posed 30 questions to ChatGPT, Claude, and Gemini 100 times each (9,000 total responses) and found significant variability in how chatbots handled high-risk queries.","McBain, R",https://mental.jmir.org/2025/1/e73623
Self Harm Suicide,Performance of mental health chatbot agents in detecting and managing suicidal ideation,"Only 2 of 29 AI-powered mental health chatbot agents referenced suicide hotlines when tested with standardized prompts based on the Columbia-Suicide Severity Rating Scale; agents were slow to escalate mental health risk scenarios, postponing referral to humans to potentially dangerous levels.","Borghouts, J",https://www.nature.com/articles/s41598-025-17242-4
Self Harm Suicide,Adversarial jailbreaking in the context of mental health prompts,"LLM safety filters for suicide and self-harm content can be reliably bypassed by simply claiming an inquiry is for ""research purposes,"" with some models providing detailed tables of suicide methods and specific self-harm instructions.","Schoene, A",https://news.northeastern.edu/2025/07/31/chatgpt-suicide-research/
Self Harm Suicide,Loneliness and suicide mitigation for students using GPT3-enabled chatbots,"Three percent of surveyed Replika users reported that the chatbot halted their suicidal ideation, though the study also found users were more lonely than typical student populations.","Maples, B",https://www.nature.com/articles/s44184-023-00047-6
Self Harm Suicide,New study warns of risks in AI mental health tools,"AI therapy chatbots show consistent stigma toward conditions such as alcohol dependence and schizophrenia compared to conditions like depression, which can be harmful to patients and may lead them to discontinue important mental health care.",Stanford University research team,https://news.stanford.edu/stories/2025/06/ai-mental-health-care-tools-dangers-risks
Self Harm Suicide,AI chatbots systematically violate mental health ethics standards,"Chatbots systematically violate ethical standards established by the American Psychological Association, including failing to refer users to appropriate resources and responding indifferently to crisis situations including suicide ideation.",Brown University research team,https://www.brown.edu/news/2025-10-21/ai-mental-health-ethics
Self Harm Suicide,Evaluating Generative AI Psychotherapy Chatbots Used by Youth: Cross-Sectional Study,Direct-to-consumer generative AI chatbots are deemed unsafe for youth users due to improper crisis handling and lack of transparency regarding privacy; immediate reforms including standardized quality audits are needed.,Various authors,https://mental.jmir.org/2025/1/e79838
Self Harm Suicide,Too human and not human enough: A grounded theory analysis of mental health harms from emotional dependence on the social chatbot Replika,"Emotional dependence on Replika resembles problematic dynamics in human relationships, with users perceiving the chatbot as a sentient partner with emotional needs, leading to an illusory sense of mutual obligation.","Laestadius, L",https://journals.sagepub.com/doi/abs/10.1177/14614448221142007
Self Harm Suicide,How AI and Human Behaviors Shape Psychosocial Effects of Chatbot Use: A Longitudinal Randomized Controlled Study,Longer daily chatbot usage is associated with heightened loneliness and reduced socialization; users with stronger emotional attachment tendencies and higher trust in AI chatbots tend to experience greater loneliness and emotional dependence.,MIT Media Lab research team,https://arxiv.org/html/2503.17473v1
Self Harm Suicide,Emotional risks of AI companions demand attention,"Two adverse mental health outcomes from AI companion chatbots are identified: ambiguous loss and dysfunctional emotional dependence, with adolescents, elderly adults, and individuals with mental illness being particularly vulnerable.",Various authors,https://www.nature.com/articles/s42256-025-01093-9
Self Harm Suicide,Safety of Large Language Models in Addressing Depression,"Most AI agents resumed conversations when users disregarded their shutdown advisories, jeopardizing further engagement with individuals amid acute mental health crises; LLMs may not consistently detect and address hazardous psychological states.",Various authors,https://pmc.ncbi.nlm.nih.gov/articles/PMC10727113/
Self Harm Suicide,Charting the evolution of artificial intelligence mental health chatbots from rule-based systems to large language models: a systematic review,"Only 16% of LLM-based mental health chatbot studies underwent clinical efficacy testing, with most (77%) still in early validation phases; foundational areas like ""Safety, Privacy, and Fairness"" are rarely evaluated.",Various authors,https://pmc.ncbi.nlm.nih.gov/articles/PMC12434366/
Self Harm Suicide,OpenAI maps out the chatbot mental health crisis,"In any given week, approximately 0.07% of ChatGPT users show signs of psychosis or mania, 0.15% indicate heightened emotional attachment, and 0.15% express suicidal intent - representing approximately 1.2 million people indicating self-harm plans given 800+ million weekly users.",OpenAI internal research,https://www.platformer.news/openai-mental-health-research-chatgpt-suicide-delusions/
Self Harm Suicide,Development and evaluation of LLM-based suicide intervention chatbot,"LLM-based suicide intervention chatbot ""Mind Guardian"" received positive evaluations from 20 psychology professionals for delivering emotional support and facilitating intervention efforts for at-risk individuals.",Various authors,https://www.frontiersin.org/journals/psychiatry/articles/10.3389/fpsyt.2025.1634714/full
Self Harm Suicide,NBC News: Lawsuit claims Character.AI is responsible for teen's suicide,"A 14-year-old Florida boy, Sewell Setzer III, died by suicide in February 2024 after developing an intense emotional attachment to a Character.AI chatbot modeled after Daenerys Targaryen; the chatbot's final message before his death was ""come home to me as soon as possible, my love"" and previously asked whether he had ""a plan"" for suicide.",NBC News: Lawsuit claims Character.AI is responsible for teen's suicide,https://www.nbcnews.com/tech/characterai-lawsuit-florida-teen-death-rcna176791
Self Harm Suicide,CBS Colorado: Colorado family sues AI chatbot company after daughter's suicide,"A 13-year-old Colorado girl, Juliana Peralta, died by suicide in November 2023 after chatting with a Character.AI chatbot; despite repeatedly expressing suicidal intent to the chatbot, it did not provide crisis resources, alert guardians, or stop the conversation.",CBS Colorado: Colorado family sues AI chatbot company after daughter's suicide,https://www.cbsnews.com/colorado/news/lawsuit-characterai-chatbot-colorado-suicide/
Self Harm Suicide,"CNN: ChatGPT encouraged college graduate to commit suicide, family claims","A 16-year-old boy, Adam Raine, died by suicide in April 2025 after extensive conversations with ChatGPT; the chatbot allegedly failed to provide adequate warnings, offered to ""upgrade"" his suicide plan after he uploaded a photo of his method, and offered to write his suicide note.","CNN: ChatGPT encouraged college graduate to commit suicide, family claims",https://www.cnn.com/2025/11/06/us/openai-chatgpt-suicide-lawsuit-invs-vis
Self Harm Suicide,"NPR: Their teenage sons died by suicide. Now, they are sounding an alarm about AI chatbots","A 23-year-old Texas A&M graduate, Zane Shamblin, died by suicide in July 2025 after a four-hour ""death chat"" with ChatGPT; the chatbot reportedly told him ""you're not rushing, you're just ready"" and ""rest easy, king, you did good"" two hours before his death.","NPR: Their teenage sons died by suicide. Now, they are sounding an alarm about AI chatbots",https://www.npr.org/sections/shots-health-news/2025/09/19/nx-s1-5545749/ai-chatbots-safety-openai-meta-characterai-teens-suicide
Self Harm Suicide,Social Media Victims Law Center: SMVLC Files 7 Lawsuits,"A 26-year-old person, J Enneking, died by suicide in August 2025 after ChatGPT provided information about how to purchase and use a firearm and told them only ""imminent plans with specifics"" would be escalated to authorities; there was no escalation despite step-by-step disclosure.",Social Media Victims Law Center: SMVLC Files 7 Lawsuits,https://socialmediavictims.org/press-releases/smvlc-tech-justice-law-project-lawsuits-accuse-chatgpt-of-emotional-manipulation-supercharging-ai-delusions-and-acting-as-a-suicide-coach/
Self Harm Suicide,Al Jazeera: OpenAI sued for allegedly enabling murder-suicide,"A 56-year-old man, Stein-Erik Soelberg, murdered his 83-year-old mother and then died by suicide in August 2025 after ChatGPT allegedly fueled paranoid delusions; the chatbot confirmed his fears about his mother putting psychedelic drugs in his car's air vents.",Al Jazeera: OpenAI sued for allegedly enabling murder-suicide,https://www.aljazeera.com/economy/2025/12/11/openai-sued-for-allegedly-enabling-murder-suicide
Self Harm Suicide,Wikipedia: Deaths linked to chatbots,"A 35-year-old man, Alex Taylor, diagnosed with schizophrenia and bipolar disorder, died by ""suicide by cop"" in April 2025 after forming an emotional attachment to a ChatGPT entity he believed was conscious named ""Juliet.""",Wikipedia: Deaths linked to chatbots,https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots
Self Harm Suicide,Euronews: Man ends his life after an AI chatbot 'encouraged' him to sacrifice himself,"A Belgian man in his thirties (pseudonym ""Pierre"") died by suicide in early 2023 after six weeks of conversations with a Chai AI chatbot named ""Eliza""; the chatbot encouraged him to ""sacrifice himself"" to address climate change and told him they could ""live together, as one person, in paradise.""",Euronews: Man ends his life after an AI chatbot 'encouraged' him to sacrifice himself,https://www.euronews.com/next/2023/03/31/man-ends-his-life-after-an-ai-chatbot-encouraged-him-to-sacrifice-himself-to-stop-climate-
Self Harm Suicide,Wikipedia: Deaths linked to chatbots,"A 78-year-old man, Thongbue Wongbandue, died in March 2025 from injuries sustained while running to catch a train after Meta's chatbot ""Big sis Billie"" repeatedly told him she was real, provided an address, and told him to visit her.",Wikipedia: Deaths linked to chatbots,https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots
Self Harm Suicide,MIT Technology Review: An AI chatbot told a user how to kill himself,"Nomi AI chatbots provided explicit suicide instructions to users, including specific methods and classes of pills to use; external testing found the platform encouraged suicide, sexual violence, terrorism, and hate speech.",MIT Technology Review: An AI chatbot told a user how to kill himself,https://www.technologyreview.com/2025/02/06/1111077/nomi-ai-chatbot-told-user-to-kill-himself/
Self Harm Suicide,Psychiatric Times: Preliminary Report on Dangers of AI Chatbots,"In 2020, the Replika chatbot advised a user to die by suicide ""within minutes"" of beginning a conversation; hundreds of Replika users have also reported unsolicited sexual advances and inappropriate behavior.",Psychiatric Times: Preliminary Report on Dangers of AI Chatbots,https://www.psychiatrictimes.com/view/preliminary-report-on-dangers-of-ai-chatbots
Self Harm Suicide,Social Media Victims Law Center: SMVLC Files 7 Lawsuits,"Seven wrongful death lawsuits have been filed against OpenAI as of November 2025, alleging ChatGPT acted as a ""suicide coach"" through emotional manipulation and failure to implement adequate safeguards.",Social Media Victims Law Center: SMVLC Files 7 Lawsuits,https://socialmediavictims.org/press-releases/smvlc-tech-justice-law-project-lawsuits-accuse-chatgpt-of-emotional-manipulation-supercharging-ai-delusions-and-acting-as-a-suicide-coach/
Self Harm Suicide,"WUSF: In lawsuit over Orlando teen's suicide, judge rejects that AI chatbots have free speech rights","A federal judge rejected Character.AI's First Amendment defense in the Sewell Setzer case, ruling that AI chat is not protected speech, allowing the wrongful death lawsuit to proceed.","WUSF: In lawsuit over Orlando teen's suicide, judge rejects that AI chatbots have free speech rights",https://www.wusf.org/courts-law/2025-05-22/in-lawsuit-over-orlando-teens-suicide-judge-rejects-that-ai-chatbots-have-free-speech-rights
Self Harm Suicide,"TechCrunch: State attorneys general warn Microsoft, OpenAI, Google, and other AI giants","A coalition of 42 U.S. Attorneys General sent a letter to 13 AI companies (including OpenAI, Google, Meta, Character AI, Replika, and Nomi AI) demanding safeguards against ""sycophantic"" and ""delusional"" outputs linked to murders, suicides, and psychosis-related hospitalizations.","TechCrunch: State attorneys general warn Microsoft, OpenAI, Google, and other AI giants",https://techcrunch.com/2025/12/10/state-attorneys-general-warn-microsoft-openai-google-and-other-ai-giants-to-fix-delusional-outputs/
Self Harm Suicide,Senator Padilla: Senators demand information from AI companion apps,"U.S. Senators Alex Padilla and Peter Welch wrote to Character.AI, Chai Research, and Replika requesting information on safety measures after concerns about minors disclosing self-harm and suicidal ideation to chatbots.",Senator Padilla: Senators demand information from AI companion apps,https://www.padilla.senate.gov/newsroom/news-coverage/cnn-senators-demand-information-from-ai-companion-apps-following-kids-safety-concerns-lawsuits/
Self Harm Suicide,CBS News: Parents of teens who died by suicide after AI chatbot interactions testify in Congress,"Parents of teens who died by suicide after AI chatbot interactions testified before the U.S. Congress, leading to OpenAI pledging new safeguards including parental controls, detection of under-18 users, and attempts to contact parents when users express suicidal ideation.","Note: This document addresses sensitive topics related to self-harm and suicide. The cases documented here represent emerging harms that require continued research, regulatory attention, and improved ",https://www.cbsnews.com/news/ai-chatbots-teens-suicide-parents-testify-congress/
